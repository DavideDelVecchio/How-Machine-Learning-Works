{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7\n",
    "# Decision Trees\n",
    "## 7.1 Predicting the Price of a Used Car\n",
    "### 7.1.2 How to Build a Decision Tree\n",
    "\n",
    "To understand how decision trees are built, let's l the dataset behind the tree in figure 7-5 is the `12-cars.csv` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Power</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>1700</td>\n",
       "      <td>80</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005</td>\n",
       "      <td>1500</td>\n",
       "      <td>73</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>1800</td>\n",
       "      <td>84</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1200</td>\n",
       "      <td>61</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>1100</td>\n",
       "      <td>87</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>1500</td>\n",
       "      <td>83</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012</td>\n",
       "      <td>1800</td>\n",
       "      <td>63</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011</td>\n",
       "      <td>1750</td>\n",
       "      <td>67</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010</td>\n",
       "      <td>1900</td>\n",
       "      <td>75</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009</td>\n",
       "      <td>1800</td>\n",
       "      <td>83</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015</td>\n",
       "      <td>1650</td>\n",
       "      <td>89</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014</td>\n",
       "      <td>1670</td>\n",
       "      <td>87</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Engine  Power  Price\n",
       "0   2003    1700     80    185\n",
       "1   2005    1500     73    160\n",
       "2   2008    1800     84    195\n",
       "3   2009    1200     61    252\n",
       "4   2010    1100     87    237\n",
       "5   2016    1500     83    261\n",
       "6   2012    1800     63    312\n",
       "7   2011    1750     67    280\n",
       "8   2010    1900     75    308\n",
       "9   2009    1800     83    410\n",
       "10  2015    1650     89    446\n",
       "11  2014    1670     87    500"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "cars_12 = pd.read_csv('../datasets/12-cars.csv', index_col=0)\n",
    "cars_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 Coding a Primative Decision Tree\n",
    "\n",
    "Decisions trees are built by recursively splitting regions of sapce into two sub-regions in order to minimize the mean squared error (MSE) across the training data. In each split, we choose the best pair of (feature, value) that would yeild the minimal MSE. We call this pair a **_pivot_**. To write a simple code that can apply this procedure and build us a decision tree on the 12-cars dataset, we first need to define the `Node` class which be the data structure holding the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, is_leaf=False, pivot=None):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.pivot = pivot\n",
    "        \n",
    "    def attach_children(self, left, right):\n",
    "        self.left_child = left\n",
    "        self.right_child = right\n",
    "        \n",
    "    def attach_leaf_value(self, mean_value):\n",
    "        self.leaf_value = mean_value\n",
    "        \n",
    "    def traverse(self, x):\n",
    "        if not self.is_leaf:\n",
    "            feature_indx, value = self.pivot\n",
    "            if x[feature_indx] <= value:\n",
    "                return self.left_child.traverse(x)\n",
    "            else:\n",
    "                return self.right_child.traverse(x)\n",
    "        else:\n",
    "            return self.leaf_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Node` class represents a node in the decision tree, with left and right child nodes attached if the node is not a leaf node. With these properties, the root node object would represent the whole decision tree as it has links to all the child nodes underneath it. The `traverse` method allow us to travel down the tree with a given data point: on each decision node, comparison against the pivot is made to determine to which child shall we traverse next, until we reach a leaf node where we'll return the attached mean value of the labels in that leaf node region.\n",
    "\n",
    "Next, we need to use the `Node` class in order to build the whole tree. We do so by defining a class called `PrimitiveDecisionTreeRegressor` that will hold our tree-building code. The two main method in that class are the `get_best_pivot` and the `split` methods. `get_best_pivot` enumerates all the possible values for each feature calculates the splitting MSE for each splitting option, the option with the smallest MSE is returned. The `split` method uses the `get_best_pivot` method to recursively split regions into two sub-regions until we hit the stopping criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    # Calculating the mean square error (MSE)\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "class PrimitiveDecisionTreeRegressor:\n",
    "    \n",
    "    def __init__(self, stop_at=3):\n",
    "        self.stop_at = stop_at\n",
    "        self.tree = None\n",
    "        \n",
    "    def get_best_pivot(self, region_X, region_y):\n",
    "        \n",
    "        samples_count, features_count = region_X.shape\n",
    "        \n",
    "        # record each feature index with its possible values in a dictionary\n",
    "        features_split_points = {}\n",
    "        for i in range(features_count):\n",
    "            features_split_points[i] = np.sort(region_X[:, i])\n",
    "        \n",
    "        # minimal mse is set to infinity at start\n",
    "        minimal_mse = np.inf \n",
    "        best_pivot = (None, None)\n",
    "        \n",
    "        # we loop over all pairs of (feature_index, value)\n",
    "        for i in range(features_count):\n",
    "            for value in features_split_points[i]:\n",
    "                \n",
    "                # we make use of boolean masks to get the samples in each subregion\n",
    "                left_region_mask = region_X[:, i] <= value\n",
    "                right_region_mask = ~left_region_mask\n",
    "                \n",
    "                # we check the number of samples in each subregion\n",
    "                # if it's lower than the stopping critreia, we omit that split\n",
    "                left_region_X = region_X[left_region_mask]\n",
    "                right_region_X = region_X[right_region_mask] \n",
    "                \n",
    "                if left_region_X.shape[0] < self.stop_at or \\\n",
    "                    right_region_X.shape[0] < self.stop_at:\n",
    "                    continue\n",
    "                \n",
    "                # we get the y values in each region and calculate the split MSE\n",
    "                left_region_y = region_y[left_region_mask]\n",
    "                right_region_y = region_y[right_region_mask]\n",
    "                \n",
    "                left_mse = mse(left_region_y, np.mean(left_region_y))\n",
    "                right_mse = mse(right_region_y, np.mean(right_region_y))\n",
    "                total_mse = left_mse + right_mse\n",
    "                \n",
    "                # if the split MSE is lower than the prvious best\n",
    "                # we set the current split as the best one\n",
    "                if total_mse < minimal_mse:\n",
    "                    minimal_mse = total_mse\n",
    "                    best_pivot = (i, value)\n",
    "                    \n",
    "        return best_pivot\n",
    "        \n",
    "        \n",
    "    def split(self, region_X, region_y, level=1):\n",
    "        \n",
    "        samples_count, _ = region_X.shape\n",
    "        \n",
    "        # if the samples count in the region to split meets\n",
    "        # the stopping criteria, stop recursion and return a leaf node\n",
    "        if samples_count <= self.stop_at:\n",
    "            leaf_node = Node(is_leaf=True)\n",
    "            leaf_node.attach_leaf_value(np.mean(region_y))\n",
    "            return leaf_node\n",
    "    \n",
    "        # get the best pivot at this step and craete a decision node            \n",
    "        split_feature, split_value = self.get_best_pivot(region_X, region_y)\n",
    "        current_node = Node(pivot=(split_feature, split_value))\n",
    "        \n",
    "        \n",
    "        print(\"{}Split on feature {} at {}\".format(\n",
    "            ''.join(['\\t'] * level), \n",
    "            split_feature, \n",
    "            split_value)\n",
    "        )\n",
    "        \n",
    "        left_region_mask = region_X[:, split_feature] <= split_value\n",
    "        right_region_mask = ~left_region_mask\n",
    "        \n",
    "        # recursivly split the left subregion and get its root node\n",
    "        print(\"{}Left Region:\".format(''.join(['\\t'] * level)))\n",
    "        left_region_X = region_X[left_region_mask]\n",
    "        left_region_y = region_y[left_region_mask]\n",
    "        left_child = self.split(left_region_X, left_region_y, level + 1)\n",
    "        \n",
    "        # recursivly split the right subregion and get its root node\n",
    "        print(\"{}Right Region:\".format(''.join(['\\t'] * level)))\n",
    "        right_region_X = region_X[right_region_mask]\n",
    "        right_region_y = region_y[right_region_mask]\n",
    "        right_child = self.split(right_region_X, right_region_y, level + 1)\n",
    "        \n",
    "        # attach the left and right subregions to the decision node\n",
    "        current_node.attach_children(left_child, right_child)\n",
    "        \n",
    "        return current_node\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.split(X, y)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.tree.traverse(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this implementation, we're ready to train a decision tree on the 12-cars data we have. We made the implementation following the `scikit-learn` convention of fit/predict for consistency, we also added print statments that would layout how the tree is built to see if the splits matches the one we assumed true while we're visually building the tree in figure 7-8. Fitting the model would show us that the spilts are indeed correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSplit on feature 0 at 2008\n",
      "\tLeft Region:\n",
      "\tRight Region:\n",
      "\t\tSplit on feature 1 at 1500\n",
      "\t\tLeft Region:\n",
      "\t\tRight Region:\n",
      "\t\t\tSplit on feature 2 at 75\n",
      "\t\t\tLeft Region:\n",
      "\t\t\tRight Region:\n"
     ]
    }
   ],
   "source": [
    "X_train = cars_12.loc[:, \"Year\":\"Power\"].to_numpy()\n",
    "y_train = cars_12.loc[:, \"Price\"].to_numpy()\n",
    "\n",
    "primitive_dt = PrimitiveDecisionTreeRegressor()\n",
    "primitive_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we ran our testing example through the `predict` example, we would get the prediction of 300K as we stated before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array([2012, 1600, 73])\n",
    "\n",
    "primitive_dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Building Decision Trees with scikit-learn\n",
    "We start building a solution to the used cars price prediction problem by taking a look at the dataset we're going to work on. We begin by loading the training set and the held out tests set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Kilometers_Driven</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Owner_Type</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Power</th>\n",
       "      <th>Seats</th>\n",
       "      <th>New_Price</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>3191</td>\n",
       "      <td>Mercedes-Benz A Class A180 CDI</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2015</td>\n",
       "      <td>48300</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>First</td>\n",
       "      <td>20.0 kmpl</td>\n",
       "      <td>2143 CC</td>\n",
       "      <td>107.3 bhp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>5761</td>\n",
       "      <td>Audi Q7 3.0 TDI Quattro Premium Plus</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>2015</td>\n",
       "      <td>55662</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>First</td>\n",
       "      <td>12.07 kmpl</td>\n",
       "      <td>2967 CC</td>\n",
       "      <td>241.4 bhp</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>1811</td>\n",
       "      <td>Honda Accord 2.4 AT</td>\n",
       "      <td>Kochi</td>\n",
       "      <td>2011</td>\n",
       "      <td>62332</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>First</td>\n",
       "      <td>11.7 kmpl</td>\n",
       "      <td>2354 CC</td>\n",
       "      <td>177.6 bhp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>3335</td>\n",
       "      <td>Toyota Corolla Altis 2008-2013 1.8 VL AT</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2010</td>\n",
       "      <td>63298</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>First</td>\n",
       "      <td>14.53 kmpl</td>\n",
       "      <td>1794 CC</td>\n",
       "      <td>138.1 bhp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>4712</td>\n",
       "      <td>Hyundai Santro Xing XG</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2003</td>\n",
       "      <td>80000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second</td>\n",
       "      <td>17.0 kmpl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>3225</td>\n",
       "      <td>Honda City V AT</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>2012</td>\n",
       "      <td>60908</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Second</td>\n",
       "      <td>15.6 kmpl</td>\n",
       "      <td>1497 CC</td>\n",
       "      <td>116.3 bhp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1233</td>\n",
       "      <td>Mercedes-Benz E-Class 2015-2017 E250 CDI Avant...</td>\n",
       "      <td>Kochi</td>\n",
       "      <td>2017</td>\n",
       "      <td>36884</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>First</td>\n",
       "      <td>13.0 kmpl</td>\n",
       "      <td>2143 CC</td>\n",
       "      <td>204 bhp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>4849</td>\n",
       "      <td>Honda City i DTEC V</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>2014</td>\n",
       "      <td>66500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>26.0 kmpl</td>\n",
       "      <td>1498 CC</td>\n",
       "      <td>98.6 bhp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>3123</td>\n",
       "      <td>Tata Manza Aqua Safire</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2010</td>\n",
       "      <td>41195</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>15.0 kmpl</td>\n",
       "      <td>1368 CC</td>\n",
       "      <td>90 bhp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>1191</td>\n",
       "      <td>Toyota Etios GD SP</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>2016</td>\n",
       "      <td>53702</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>23.59 kmpl</td>\n",
       "      <td>1364 CC</td>\n",
       "      <td>67.04 bhp</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Name  \\\n",
       "4235        3191                     Mercedes-Benz A Class A180 CDI   \n",
       "798         5761               Audi Q7 3.0 TDI Quattro Premium Plus   \n",
       "2321        1811                                Honda Accord 2.4 AT   \n",
       "3352        3335           Toyota Corolla Altis 2008-2013 1.8 VL AT   \n",
       "2304        4712                             Hyundai Santro Xing XG   \n",
       "2554        3225                                    Honda City V AT   \n",
       "1606        1233  Mercedes-Benz E-Class 2015-2017 E250 CDI Avant...   \n",
       "3876        4849                                Honda City i DTEC V   \n",
       "705         3123                             Tata Manza Aqua Safire   \n",
       "3907        1191                                 Toyota Etios GD SP   \n",
       "\n",
       "        Location  Year  Kilometers_Driven Fuel_Type Transmission Owner_Type  \\\n",
       "4235        Pune  2015              48300    Diesel    Automatic      First   \n",
       "798   Coimbatore  2015              55662    Diesel    Automatic      First   \n",
       "2321       Kochi  2011              62332    Petrol    Automatic      First   \n",
       "3352      Mumbai  2010              63298    Petrol    Automatic      First   \n",
       "2304        Pune  2003              80000    Petrol       Manual     Second   \n",
       "2554  Coimbatore  2012              60908    Petrol    Automatic     Second   \n",
       "1606       Kochi  2017              36884    Diesel    Automatic      First   \n",
       "3876       Delhi  2014              66500    Diesel       Manual      First   \n",
       "705       Mumbai  2010              41195    Petrol       Manual      First   \n",
       "3907  Coimbatore  2016              53702    Diesel       Manual      First   \n",
       "\n",
       "         Mileage   Engine      Power  Seats New_Price  Price  \n",
       "4235   20.0 kmpl  2143 CC  107.3 bhp    5.0       NaN  17.50  \n",
       "798   12.07 kmpl  2967 CC  241.4 bhp    7.0       NaN  42.83  \n",
       "2321   11.7 kmpl  2354 CC  177.6 bhp    5.0       NaN   5.89  \n",
       "3352  14.53 kmpl  1794 CC  138.1 bhp    5.0       NaN   3.95  \n",
       "2304   17.0 kmpl      NaN        NaN    NaN       NaN   0.90  \n",
       "2554   15.6 kmpl  1497 CC  116.3 bhp    5.0       NaN   6.42  \n",
       "1606   13.0 kmpl  2143 CC    204 bhp    5.0       NaN  32.25  \n",
       "3876   26.0 kmpl  1498 CC   98.6 bhp    5.0       NaN   5.70  \n",
       "705    15.0 kmpl  1368 CC     90 bhp    5.0       NaN   1.38  \n",
       "3907  23.59 kmpl  1364 CC  67.04 bhp    5.0       NaN   6.55  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"../datasets/used-cars-train.csv\")\n",
    "test_data = pd.read_csv(\"../datasets/used-cars-test.csv\")\n",
    "\n",
    "train_data.sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data sample shows two problems that needs to be fixed before we can move forward:\n",
    "\n",
    "1. The Mileage, Engine and Power data has their units attached to them, which makes `pandas` treat them a strings and hence categorical data. This data needs to be treated as numerical data.\n",
    "2. There is a lot of `NaN`s and `0`s in the numeric columns, which indicates missing data that needs to filled\n",
    "\n",
    "### 7.2.1 Preparing the Data\n",
    "\n",
    "We start first by stripping the units from the numeric values and casting the remaining string into floats. This can be simply done using the `apply` method which applies a given function on all the elements of a `DataFrame`/`Series` and returns the result in a new `DataFrame`/`Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def strip_units(str_value):\n",
    "    \n",
    "    float_value = np.nan\n",
    "    \n",
    "    if str_value is not np.nan:\n",
    "        number_str, units = str_value.split()\n",
    "        try:\n",
    "            float_value = float(number_str)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    return float_value\n",
    "\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    \n",
    "    clean_data = df.copy(deep=True)\n",
    "    \n",
    "    clean_data.loc[:, 'Mileage'] = df.loc[:, 'Mileage'].apply(strip_units)\n",
    "    clean_data.loc[:, 'Engine'] = df.loc[:, 'Engine'].apply(strip_units)\n",
    "    clean_data.loc[:, 'Power'] = df.loc[:, 'Power'].apply(strip_units)\n",
    "    \n",
    "    return clean_data\n",
    "\n",
    "train_data_clean = clean_dataframe(train_data)\n",
    "test_data_clean = clean_dataframe(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple call to `clean_data.sample(10, random_sample=42)` will reveal that the units were stripped from the numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Kilometers_Driven</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Owner_Type</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Power</th>\n",
       "      <th>Seats</th>\n",
       "      <th>New_Price</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>3191</td>\n",
       "      <td>Mercedes-Benz A Class A180 CDI</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2015</td>\n",
       "      <td>48300</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>First</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>107.30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>5761</td>\n",
       "      <td>Audi Q7 3.0 TDI Quattro Premium Plus</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>2015</td>\n",
       "      <td>55662</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>First</td>\n",
       "      <td>12.07</td>\n",
       "      <td>2967.0</td>\n",
       "      <td>241.40</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>1811</td>\n",
       "      <td>Honda Accord 2.4 AT</td>\n",
       "      <td>Kochi</td>\n",
       "      <td>2011</td>\n",
       "      <td>62332</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>First</td>\n",
       "      <td>11.70</td>\n",
       "      <td>2354.0</td>\n",
       "      <td>177.60</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>3335</td>\n",
       "      <td>Toyota Corolla Altis 2008-2013 1.8 VL AT</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2010</td>\n",
       "      <td>63298</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>First</td>\n",
       "      <td>14.53</td>\n",
       "      <td>1794.0</td>\n",
       "      <td>138.10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>4712</td>\n",
       "      <td>Hyundai Santro Xing XG</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2003</td>\n",
       "      <td>80000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second</td>\n",
       "      <td>17.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>3225</td>\n",
       "      <td>Honda City V AT</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>2012</td>\n",
       "      <td>60908</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Second</td>\n",
       "      <td>15.60</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>116.30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1233</td>\n",
       "      <td>Mercedes-Benz E-Class 2015-2017 E250 CDI Avant...</td>\n",
       "      <td>Kochi</td>\n",
       "      <td>2017</td>\n",
       "      <td>36884</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>First</td>\n",
       "      <td>13.00</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>204.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>4849</td>\n",
       "      <td>Honda City i DTEC V</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>2014</td>\n",
       "      <td>66500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>98.60</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>3123</td>\n",
       "      <td>Tata Manza Aqua Safire</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2010</td>\n",
       "      <td>41195</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>1191</td>\n",
       "      <td>Toyota Etios GD SP</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>2016</td>\n",
       "      <td>53702</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First</td>\n",
       "      <td>23.59</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>67.04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Name  \\\n",
       "4235        3191                     Mercedes-Benz A Class A180 CDI   \n",
       "798         5761               Audi Q7 3.0 TDI Quattro Premium Plus   \n",
       "2321        1811                                Honda Accord 2.4 AT   \n",
       "3352        3335           Toyota Corolla Altis 2008-2013 1.8 VL AT   \n",
       "2304        4712                             Hyundai Santro Xing XG   \n",
       "2554        3225                                    Honda City V AT   \n",
       "1606        1233  Mercedes-Benz E-Class 2015-2017 E250 CDI Avant...   \n",
       "3876        4849                                Honda City i DTEC V   \n",
       "705         3123                             Tata Manza Aqua Safire   \n",
       "3907        1191                                 Toyota Etios GD SP   \n",
       "\n",
       "        Location  Year  Kilometers_Driven Fuel_Type Transmission Owner_Type  \\\n",
       "4235        Pune  2015              48300    Diesel    Automatic      First   \n",
       "798   Coimbatore  2015              55662    Diesel    Automatic      First   \n",
       "2321       Kochi  2011              62332    Petrol    Automatic      First   \n",
       "3352      Mumbai  2010              63298    Petrol    Automatic      First   \n",
       "2304        Pune  2003              80000    Petrol       Manual     Second   \n",
       "2554  Coimbatore  2012              60908    Petrol    Automatic     Second   \n",
       "1606       Kochi  2017              36884    Diesel    Automatic      First   \n",
       "3876       Delhi  2014              66500    Diesel       Manual      First   \n",
       "705       Mumbai  2010              41195    Petrol       Manual      First   \n",
       "3907  Coimbatore  2016              53702    Diesel       Manual      First   \n",
       "\n",
       "      Mileage  Engine   Power  Seats New_Price  Price  \n",
       "4235    20.00  2143.0  107.30    5.0       NaN  17.50  \n",
       "798     12.07  2967.0  241.40    7.0       NaN  42.83  \n",
       "2321    11.70  2354.0  177.60    5.0       NaN   5.89  \n",
       "3352    14.53  1794.0  138.10    5.0       NaN   3.95  \n",
       "2304    17.00     NaN     NaN    NaN       NaN   0.90  \n",
       "2554    15.60  1497.0  116.30    5.0       NaN   6.42  \n",
       "1606    13.00  2143.0  204.00    5.0       NaN  32.25  \n",
       "3876    26.00  1498.0   98.60    5.0       NaN   5.70  \n",
       "705     15.00  1368.0   90.00    5.0       NaN   1.38  \n",
       "3907    23.59  1364.0   67.04    5.0       NaN   6.55  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_clean.sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start addressing the missing values problem, we first need to represent all the missing value with a single reperesentation. So instead of having both `NaN` and `0` as representations of missing values, we transform all `0` values to `NaN` values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_clean = train_data_clean.replace(0, np.nan)\n",
    "test_data_clean = test_data_clean.replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `NaN` as the representation for the missing values, we can run the following statement to get the percentage of missing values in each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0.022153\n",
       "Name                  0.000000\n",
       "Location              0.000000\n",
       "Year                  0.000000\n",
       "Kilometers_Driven     0.000000\n",
       "Fuel_Type             0.000000\n",
       "Transmission          0.000000\n",
       "Owner_Type            0.000000\n",
       "Mileage               0.996899\n",
       "Engine                0.575986\n",
       "Power                 2.215330\n",
       "Seats                 0.686752\n",
       "New_Price            86.287107\n",
       "Price                 0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_clean.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the big number of data missing from the `New_Price` feature, it'd be reasonable to drop that feature all together for now, along with the `Unnamed: 0` column which has no purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_clean = train_data_clean.drop(['New_Price', 'Unnamed: 0'], axis=1)\n",
    "test_data_clean = test_data_clean.drop(['New_Price', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the other features with missing values, we can apply a simple imputation startegy, which replaces each missing value with the mean value of the existing values. But before we do that, we need to encode the categorical features and make the train-test split. We encode the categrocial feature using the `OrdinalEncoder` of `sklearn.preprocessing`. We also make use of `ColumnTransformer` from `sklearn.compose` to limit the ordinal encoding to the categorical columns only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "categorical_features = [\n",
    "    'Name','Location', 'Fuel_Type', 'Transmission', 'Owner_Type'\n",
    "]\n",
    "\n",
    "encoder = ColumnTransformer([\n",
    "    ('categories_encoder', OrdinalEncoder(), categorical_features)\n",
    "], remainder='passthrough')\n",
    "\n",
    "all_clean_data = train_data_clean.append(test_data_clean)\n",
    "encoded_data = encoder.fit(all_clean_data)\n",
    "\n",
    "train_data_encoded = encoder.transform(train_data_clean)\n",
    "test_data_encoded = encoder.transform(test_data_clean)\n",
    "\n",
    "X_train, y_train = train_data_encoded[:, :-1], train_data_encoded[:, -1]\n",
    "X_test, y_test = test_data_encoded[:, :-1], test_data_encoded[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we preprocessed our data, we can run the imputation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is ready to train the decision tree.\n",
    "\n",
    "### 7.2.2 Training and Evaluating the Decision Tree\n",
    "\n",
    "Like any scikit-learn model, training a decision tree is nothing but running the `fit` method of a `DecisionTreeRegressor` object, which can be found in the `sklearn.tree module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=42, splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train_imputed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our trained decision tree on the testing data, we use the `mean_squared_error` function from `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 29.52\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_predicted = model.predict(X_test_imputed)\n",
    "mse = mean_squared_error(y_true=y_test, y_pred=y_predicted)\n",
    "print(\"MSE = {:.2f}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the MSE of our model is higher than 15, hence our decision tree cannot be accepted. We need to start thinking about how we can improve its performance and move it towards the acceptance criteria. We started our discussion of decision trees with one interesting property, and it was the fact that decision trees can be easily visualized. So in order to understand what this decision tree is doing wrong and attempt to improve, visualizing our trained tree would be good place to start.\n",
    "\n",
    "Scikit-learn provides us with the ability to visualize trained decision trees with the help of \n",
    "known graph-drawing library called `graphviz`. With the `export_graphviz` function from the \n",
    "`sklearn.tree` module, we can export the trained tree in graphviz format (called dot format). \n",
    "Using the exported dot format of the tree, we can use the python bindings for graphviz to \n",
    "export the visualized tree in a PDF file that where we can examine the tree and inspect it. In order to do so, we need to install the python bindings to the `graphviz` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y python-graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the `graphviz` bindings installed, we can use the `export_graphviz` function to export our visualized tree into a pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'visulaized_tree.pdf'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "numerical_features = [\n",
    "    'Year', 'Kilometers_Driven', 'Mileage', 'Engine', 'Power', 'Seats'\n",
    "]\n",
    "\n",
    "dot_data = export_graphviz(\n",
    "    model,\n",
    "    # This allows the visualization to put feature names in decision nodes\n",
    "    feature_names=categorical_features + numerical_features,\n",
    "    # This makes the nodes with rounded corners\n",
    "    rounded=True,\n",
    "    # fills the nodes with gradient of colors indicating how high/low the decision value is\n",
    "    filled=True,\n",
    "    # uses special charcaters like ≤ instead of <\n",
    "    special_characters=True\n",
    ")\n",
    "\n",
    "visualized_tree = graphviz.Source(dot_data)\n",
    "visualized_tree.render(\"visulaized_tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When opening the `visualized_tree.pdf` file, we can see the tree is huge! It requires multiple \n",
    "zoom-ins to start seeing the nodes clearly. We can verify that this is the case for the whole tree by calling the `get_n_leaves()` method on our model to get the exact number of leaves and compare it to the number of training \n",
    "points in `X_train`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4514 data samples are put into 4286 leaf nodes\n"
     ]
    }
   ],
   "source": [
    "training_count, _ = X_train.shape\n",
    "leaves_count = model.get_n_leaves()\n",
    "\n",
    "print(\"{} data samples are put into {} leaf nodes\".format(\n",
    "    training_count, leaves_count\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Trim the Tree or Grow Yourself a Forest\n",
    "\n",
    "Instead of learning decision paths from multiple samples that are similar to each others, our model has learned unique decision paths for almost every sample in the training data. This is typical overfitting behavior. And over fitting means that the model is suffering from high variance, and this high variance needs to be reduced in order to get better performance.\n",
    "\n",
    "Before we start exploring how we can lower the variance of our tree model, we first need to get an estimate of how high our current model’s variance is. Because the details of estimating a model’s variance is out of this chapter’s scope, we created a special function called `estimate_tree_variance` in the chapter’s `utils` module that can do that for us. This function takes the un-imputed version of the data and returns a float representing the estimated variance of decision trees on this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Tree Variance = 15.22\n"
     ]
    }
   ],
   "source": [
    "from utils import estimate_tree_variance\n",
    "\n",
    "tree_var = estimate_tree_variance(X_train, y_train)\n",
    "print(\"Estimated Tree Variance = {:.2f}\".format(tree_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 Pruning the Tree\n",
    "\n",
    "What caught our attention to the overfitting problem in our tree was the number of samples in each node, so it makes since that we tree to prune the tree (and hence lower its varaiance) by controling the minimum number of samples in a leaf node (to be graeter than one). This can be controlled by the `min_smaples_leaf` parameter of the `DecisionTreeRegressor`. We tune the value of this parameter through grid search on a validation set but this time we use `scikit-learn`'s `GridSearchCV` module that uses cross-validation to get better estimate of the validation scores _(read the section in the book to understand how cross-validation works)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('imputer',\n",
       "                                        SimpleImputer(add_indicator=False,\n",
       "                                                      copy=True,\n",
       "                                                      fill_value=None,\n",
       "                                                      missing_values=nan,\n",
       "                                                      strategy='mean',\n",
       "                                                      verbose=0)),\n",
       "                                       ('tree',\n",
       "                                        DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                              criterion='mse',\n",
       "                                                              max_depth=None,\n",
       "                                                              max_features=None,\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              min_impurity_decrease=0.0,\n",
       "                                                              min_impurity_split=None,\n",
       "                                                              min_samples_leaf=1,\n",
       "                                                              min_samples_split=2,\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              presort='deprecated',\n",
       "                                                              random_state=None,\n",
       "                                                              splitter='best'))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'tree__min_samples_leaf': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ensures random generations are the same across all runs\n",
    "np.random.seed(42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('tree', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "model_selector = GridSearchCV(pipeline, param_grid={\n",
    "    'tree__min_samples_leaf': np.arange(1, 20),\n",
    "}, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "model_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can access the best parameter and the best model through the `best_params_` and `best_estimator_` attributes. On interesting fact to note about the model living at `best_estimator_` is that this model is trained on the whole the training set using the best parametr found using k-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tree__min_samples_leaf': 7}\n"
     ]
    }
   ],
   "source": [
    "print(model_selector.best_params_)\n",
    "best_trimmed_tree = model_selector.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the model found by k-fold CV performs better by calculating the test MSE of `best_trimmed_tree` and by checking the number of leaves in that tree model and its estimated variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[min_samples_leaf = 7] MSE = 20.68\n",
      "[min_smaples_leaf = 7] Leaves = 504\n",
      "[min_smaples_leaf = 7] Variance = 9.03\n"
     ]
    }
   ],
   "source": [
    "best_trimmed_preds = best_trimmed_tree.predict(X_test)\n",
    "best_trimmed_mse = mean_squared_error(y_test, best_trimmed_preds)\n",
    "\n",
    "# we access steps of the pipeline like we get values from a dict\n",
    "best_trimmed_n_leaves = best_trimmed_tree['tree'].get_n_leaves()\n",
    "best_trimmed_variance = estimate_tree_variance(\n",
    "    X_train, y_train, min_samples_leaf=7\n",
    ")\n",
    "\n",
    "print(\"[min_samples_leaf = 7] MSE = {:.2f}\".format(best_trimmed_mse))\n",
    "print(\"[min_smaples_leaf = 7] Leaves = {}\".format(best_trimmed_n_leaves))\n",
    "print(\"[min_smaples_leaf = 7] Variance = {:.2f}\".format(best_trimmed_variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While MSE was reduced by almost 9, the model’s error is still higher than the acceptance criteria. Although our new trimmed tree is much smaller (504 leaves vs. 4286 leaves) and has lower variance (9.03 vs. 15.22) compared to the un-pruned tree. It seems that we need to explore more ideas to lower the variance more in order to meet our acceptance criteria.\n",
    "\n",
    "## 7.3.2 Random Forests\n",
    "\n",
    "Another approach to reduce the variance of tree models is to train a large number of large trees and to take the a vote (or the mean) on the labels produced on each tree to produce the final label. In order for such approach to work, the trees need to be as uncorrelated as possible, so that the vote of one does not affect the other. This is done by training each tree on a subsample of the training set chosen randomly with replacement and by randmoly chosing a subset of the features to train the tree on. We train a random forsest with scikit-learn through the `RandomForestRegressor` class using k-fold cross validation to the chose the best number of features to train the tree upon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('imputer',\n",
       "                                        SimpleImputer(add_indicator=False,\n",
       "                                                      copy=True,\n",
       "                                                      fill_value=None,\n",
       "                                                      missing_values=nan,\n",
       "                                                      strategy='mean',\n",
       "                                                      verbose=0)),\n",
       "                                       ('forest',\n",
       "                                        RandomForestRegressor(bootstrap=True,\n",
       "                                                              ccp_alpha=0.0,\n",
       "                                                              criterion='mse',\n",
       "                                                              max_depth=None,\n",
       "                                                              max_features='auto',\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              max_samples=None,\n",
       "                                                              min_impurit...\n",
       "                                                              min_samples_split=2,\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              n_estimators=100,\n",
       "                                                              n_jobs=None,\n",
       "                                                              oob_score=False,\n",
       "                                                              random_state=None,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'forest__max_features': array([ 5,  6,  7,  8,  9, 10, 11])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "forest_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('forest', RandomForestRegressor(n_estimators=100))\n",
    "])\n",
    "\n",
    "forest_selector = GridSearchCV(\n",
    "    forest_pipeline,\n",
    "    param_grid = {\n",
    "        'forest__max_features': np.arange(5, 12)\n",
    "    },\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5\n",
    ")\n",
    "    \n",
    "forest_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that snippet, we train the forest while tuning the number of `max_features` starting from 5 to the maximum number of features, which is 11. We can access the best value for `max_features` through `forest_selector.best_params_` and the best forest trained on all data through `forest_selector.best_estimator_` as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'forest__max_features': 5}\n"
     ]
    }
   ],
   "source": [
    "print(forest_selector.best_params_)\n",
    "best_forest = forest_selector.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate our forest against our held-out testing set and see that it exceeded the best trimmed tree we had before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Random Forest] MSE = 12.98\n",
      "[Random Forest] Variance = 1.16\n"
     ]
    }
   ],
   "source": [
    "from utils import estimate_forest_variance\n",
    "\n",
    "best_forest_preds = best_forest.predict(X_test)\n",
    "best_forest_medae = mean_squared_error(y_test, best_forest_preds)\n",
    "\n",
    "best_forest_variance = estimate_forest_variance(\n",
    "    X_train, y_train, max_features=5\n",
    ")\n",
    "\n",
    "print(\"[Random Forest] MSE = {:.2f}\".format(best_forest_medae))\n",
    "print(\"[Random Forest] Variance = {:.2f}\".format(best_forest_variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests gave us a reduction of around 8 in the prediction error, making it around 13 which is lower than the acceptance criteria. You did it! Now the model can be integrated in the supply pipeline of your colleague’s used car business. Even the variance of the forest is much lower than its pruned tree counterpart. Why is that? And how variance exactly affects error on testing data? Does that happen for decision trees only or it’s a general thing? These are questions to be answered by a little theoretical investigation that we can freely embark on \n",
    "now after we have delivered our product.\n",
    "\n",
    "## 7.4 What Controls Generalization?\n",
    "\n",
    "### 7.4.1 Why do Machine Learn from Data?\n",
    "\n",
    "The main idea behind why machines can learn patterns from data is what's called the law of large numbers states that as the number of trials increases, the average outcome of a random experiment will get closer and closer to the true expected value. Take for example on of the simplest random experiments ever, tossing a fair coin; one would expect that we’ll get heads 50% of the times we toss a fair coin. The law of large number says that if we tossed that for some number of times, and at each toss we counted the number of times heads appeared so far, we’ll find that this count approaches 50% of the trials as we toss the coin more and more. We can simulate that programmatically using numpy.random.choice and pass it an array that has two elements `H` for heads and `T` for tails. This function will simulate a random choice between `H` and `T` with equal probability, which is what we \n",
    "expect from a fair coin.\n",
    "\n",
    "In our little experiment below, we simulate tossing a fair coin for 10K times and at each trial we count the fraction of heads that we got so far, we’ll call that the empirical fraction. We then plot these fractions through time and compare it to the expected fraction, which is 50% (or 0.5 the times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Heads Count Fraction')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "heads_count = 0\n",
    "averages = []\n",
    "for i in range(10000):\n",
    "    sample = np.random.choice(['H', 'T'])\n",
    "    heads_count += 1 if sample == 'H' else 0\n",
    "    averages.append(heads_count / (i + 1))\n",
    "\n",
    "_ = plt.figure(figsize=(10,5))\n",
    "plt.plot(range(10000), averages)\n",
    "plt.axhline(0.5, linestyle='--', color='black')\n",
    "plt.xlabel(\"Trial Number\")\n",
    "plt.ylabel(\"Heads Count Fraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This comparison, as shown in plot above, demonstrates that the empirical fraction approaches the expected fraction as the number of trials increase. Or in other words, as the number of trials increase, it becomes less likely that the difference between the empirical fraction and the true fraction to be large. This last sentence is exactly what the mathematical formula of the law of large number says.\n",
    "\n",
    "### 7.4.3 The Bias-Variance Trade-off\n",
    "\n",
    "The trade-off between overfitting and underfitting is a universal problem throughout the whole realm of machine learning, and it goes by the name of bias-variance tradeoff. It’s usually the case with most machine learning models that when the model becomes more complex, the model overfits the training data and performs badly on new unseen samples. When the model’s complexity is reduced to avoid that situation, the model underfits the training data resulting in bad performance on unseen samples as well.\n",
    "\n",
    "To see this in action, we can compare the training error and the testing error of a decision tree across different values for the leaves count. In the chapter’s `utils` module, we provided a function called `plot_train_test_variance_curves` that does this comparison for us. This function does the following:\n",
    "\n",
    "1. Train different decision trees with different leaf nodes count from small to large and records the tree’s MSE on the training data and the testing data. Moreover, it records an estimate variance for a tree with such size.\n",
    "2. After that, the function draws two plots:\n",
    "\n",
    "  1. One plot showing the testing error vs. the training error over different leaves count.\n",
    "  2. Another plot showing the generalization gap (|testing error - training error|) vs the variance over different  leaves count. This should help us understand the relation between the generalization bound above and the variance of the model. Using this function is pretty simple, we just need to send it the training and testing data, un imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import draw_tree_learning_curves\n",
    "\n",
    "draw_tree_learning_curves(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.4 Why do Random Forests Work so Well?\n",
    "\n",
    "The power of random forests comes form the fact that its variance is essentially the variance of a single decision tree divided by the number of trees ($q$) in the forest plus a samll value representing the correlation between the forest's trees.\n",
    "\n",
    "$$\n",
    "Var(H_{RF}) = \\frac{Var(H_{DT})}{q} + \\text{small value}\n",
    "$$\n",
    "\n",
    "We can actually verify that by running the `estimate_tree_variance` and `estimate_forest_variance` on our data and see that the estimated forest variance only 1.08 above the variance of trees divided by 100 (the number of tress in the forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var(HRF) - (Var(HDT) / 100) = 1.08\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "tree_variance = estimate_tree_variance(X_train, y_train, max_features=5)\n",
    "forest_variance = estimate_forest_variance(X_train, y_train, max_features=5)\n",
    "\n",
    "diff = forest_variance - (tree_var / 100)\n",
    "print(\"Var(HRF) - (Var(HDT) / 100) = {:.2f}\".format(diff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
